# -*- coding: utf-8 -*-
"""MFCC 2D IMAGE

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fLbbpxE4gzB6Z5jXCaFt_uTtzGpCJgeG
"""

import os
import zipfile
import random
import shutil
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from shutil import copyfile
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')

local_zip = '/content/drive/MyDrive/MFCC 20k bee dataset.zip'
zip_ref   = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp')
zip_ref.close()

# Folder paths for training, validation, and test data
TRAINING_DIR = "/tmp/MFCC 20k bee dataset/train"
VALIDATION_DIR = "/tmp/MFCC 20k bee dataset/val"
TEST_DIR = "/tmp/MFCC 20k bee dataset/test"

TRAINING_Queen_DIR = os.path.join(TRAINING_DIR, "mfccs_Queen/")
VALIDATION_Queen_DIR = os.path.join(VALIDATION_DIR, "mfccs_Queen/")
TEST_Queen_DIR = os.path.join(TEST_DIR, "mfccs_Queen/")

TRAINING_Queenless_DIR = os.path.join(TRAINING_DIR, "mfccs_Queenless/")
VALIDATION_Queenless_DIR = os.path.join(VALIDATION_DIR, "mfccs_Queenless/")
TEST_Queenless_DIR = os.path.join(TEST_DIR, 'mfccs_Queenless/')

def train_val_generators(TRAINING_DIR, VALIDATION_DIR, TEST_DIR):
    train_datagen = ImageDataGenerator(rescale=1./255)
    train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,
                                                        batch_size=128,
                                                        class_mode='binary',
                                                        target_size=(496, 369))

    test_datagen = ImageDataGenerator(rescale=1./255)
    test_generator = test_datagen.flow_from_directory(directory=TEST_DIR,
                                                      batch_size=128,
                                                      class_mode='binary',
                                                      target_size=(496, 369))

    validation_datagen = ImageDataGenerator(rescale=1./255)
    validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,
                                                                  batch_size=128,
                                                                  class_mode='binary',
                                                                  target_size=(496, 369))

    return train_generator, validation_generator, test_generator

train_generator, validation_generator, test_generator = train_val_generators(TRAINING_DIR, VALIDATION_DIR, TEST_DIR)

def create_model():
  model = tf.keras.models.Sequential([
      tf.keras.layers.Conv2D(32,(3,3),activation='relu',input_shape=(496,369,3)),
      tf.keras.layers.MaxPooling2D(2,2),
      tf.keras.layers.Conv2D(64,(3,3),activation='relu'),
      tf.keras.layers.MaxPooling2D(2,2),
      tf.keras.layers.Conv2D(128,(3,3),activation='relu'),
      tf.keras.layers.MaxPooling2D(2,2),
      tf.keras.layers.Flatten(),
      tf.keras.layers.Dense(256, activation='relu'),
      tf.keras.layers.Dense(1,activation='sigmoid')
      ])


  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
                loss=['binary_crossentropy'],
                metrics=['accuracy'])

  return model

from tensorflow.keras.callbacks import EarlyStopping

model = create_model()

early_stopping_callback = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)

history = model.fit(train_generator,
                    epochs=100,
                    verbose=1,
                    validation_data=validation_generator,
                    callbacks=[early_stopping_callback])

import numpy as np
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.metrics import precision_score

# Generate predictions for the validation set
validation_data = validation_generator
y_true = validation_data.classes
y_pred = model.predict(validation_data)
y_pred = np.round(y_pred).flatten()

test_loss, test_accuracy = model.evaluate(test_generator)



# Print the test loss and test accuracy
print("Test Loss:", test_loss)
print("Test Accuracy:", test_accuracy)

# Compute the confusion matrix
cm = confusion_matrix(y_true, y_pred)
print("Confusion Matrix:")
print(cm)

report = classification_report(y_true, y_pred)
print("Classification Report:")
print(report)

from sklearn.metrics import precision_score

# Get predictions on the test data
y_pred = model.predict(test_generator)

# Convert the predicted probabilities to class labels
y_pred_classes = (y_pred > 0.5).astype(int)

# Get true labels for the test data
y_true = test_generator.classes

# Calculate precision
precision = precision_score(y_true, y_pred_classes)

# Display precision
print("Precision:", precision)

model.save('/content/drive/MyDrive/Models/CNN_MFCC_IMAGE2D.h5')

acc=history.history['accuracy']
val_acc=history.history['val_accuracy']
loss=history.history['loss']
val_loss=history.history['val_loss']

epochs=range(len(acc))

plt.plot(epochs, acc, 'r', "Training Accuracy")
plt.plot(epochs, val_acc, 'b', "Validation Accuracy")
plt.title('Training and validation accuracy')
plt.show()
print("")

plt.plot(epochs, loss, 'r', "Training Loss")
plt.plot(epochs, val_loss, 'b', "Validation Loss")
plt.show()

